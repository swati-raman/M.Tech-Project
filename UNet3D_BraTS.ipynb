{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6lXO9Ojeyl4O",
    "outputId": "172bc2cb-2f2c-423b-fa70-b7675e0eaddd"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import PIL\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import data\n",
    "from skimage.util import montage \n",
    "import skimage.transform as skTrans\n",
    "from skimage.transform import rotate\n",
    "from skimage.transform import resize\n",
    "from PIL import Image, ImageOps  \n",
    "\n",
    "\n",
    "# neural imaging\n",
    "import nilearn as nl\n",
    "import nibabel as nib\n",
    "import nilearn.plotting as nlplt\n",
    "#!pip install git+https://github.com/miykael/gif_your_nifti # nifti to gif #already done\n",
    "import gif_your_nifti.core as gif2nif\n",
    "\n",
    "\n",
    "# ml libs\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.callbacks import CSVLogger\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "\n",
    "# Make numpy printouts easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U numpy scipy scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conda update mkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xWHQPhzH4SsU",
    "outputId": "dc33cf13-1459-4e97-d74c-262d59b773e8"
   },
   "outputs": [],
   "source": [
    "# DEFINE seg-areas  \n",
    "SEGMENT_CLASSES = {\n",
    "    0 : 'NOT tumor',\n",
    "    1 : 'NECROTIC/CORE', # or NON-ENHANCING tumor CORE\n",
    "    2 : 'EDEMA',\n",
    "    3 : 'ENHANCING' # original 4 -> converted into 3 later\n",
    "}\n",
    "\n",
    "# there are 155 slices per volume\n",
    "# to start at 25 and use 145 slices means we will skip the first 5 and last 5 \n",
    "VOLUME_SLICES = 60 \n",
    "VOLUME_START_AT = 22 # first slice of volume that we will include"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9DmEB6JG6H7D"
   },
   "source": [
    "! cp kaggle.json ~/.kaggle/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qnnjJDRz5Cp9"
   },
   "source": [
    "! chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fj4yPXgT5Cfq",
    "outputId": "6c1d2c2f-b68b-41ca-f963-47f4356ea153"
   },
   "source": [
    "!kaggle datasets download -d awsaf49/brats20-dataset-training-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UXNn_NOX5Cy0",
    "outputId": "29e74d03-c86c-45d7-fd30-89f9b16bcd88"
   },
   "source": [
    "#unzipping the zip files and deleting the zip files\n",
    "!unzip \\*.zip  && rm *.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "id": "opkYbho05DPG",
    "outputId": "7df83aeb-1da2-4212-c73d-6e2d7468eef2"
   },
   "outputs": [],
   "source": [
    "TRAIN_DATASET_PATH = '/Users/swatiraman/Downloads/archive-2/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/'\n",
    "VALIDATION_DATASET_PATH =  '/Users/swatiraman/Downloads/archive-2/BraTS2020_ValidationData/MICCAI_BraTS2020_ValidationData/'\n",
    "\n",
    "test_image_flair=nib.load(TRAIN_DATASET_PATH + 'BraTS20_Training_001/BraTS20_Training_001_flair.nii').get_fdata()\n",
    "test_image_t1=nib.load(TRAIN_DATASET_PATH + 'BraTS20_Training_001/BraTS20_Training_001_t1.nii').get_fdata()\n",
    "test_image_t1ce=nib.load(TRAIN_DATASET_PATH + 'BraTS20_Training_001/BraTS20_Training_001_t1ce.nii').get_fdata()\n",
    "test_image_t2=nib.load(TRAIN_DATASET_PATH + 'BraTS20_Training_001/BraTS20_Training_001_t2.nii').get_fdata()\n",
    "test_mask=nib.load(TRAIN_DATASET_PATH + 'BraTS20_Training_001/BraTS20_Training_001_seg.nii').get_fdata()\n",
    "\n",
    "\n",
    "fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1,5, figsize = (20, 10))\n",
    "slice_w = 25\n",
    "ax1.imshow(test_image_flair[:,:,test_image_flair.shape[0]//2-slice_w], cmap = 'gray')\n",
    "ax1.set_title('Image flair')\n",
    "ax2.imshow(test_image_t1[:,:,test_image_t1.shape[0]//2-slice_w], cmap = 'gray')\n",
    "ax2.set_title('Image t1')\n",
    "ax3.imshow(test_image_t1ce[:,:,test_image_t1ce.shape[0]//2-slice_w], cmap = 'gray')\n",
    "ax3.set_title('Image t1ce')\n",
    "ax4.imshow(test_image_t2[:,:,test_image_t2.shape[0]//2-slice_w], cmap = 'gray')\n",
    "ax4.set_title('Image t2')\n",
    "ax5.imshow(test_mask[:,:,test_mask.shape[0]//2-slice_w])\n",
    "ax5.set_title('Mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 609
    },
    "id": "88O_IPL9fsLA",
    "outputId": "0868465f-e4be-4ba9-ca48-0eff736199cd"
   },
   "outputs": [],
   "source": [
    "# Skip 50:-50 slices since there is not much to see\n",
    "fig, ax1 = plt.subplots(1, 1, figsize = (15,15))\n",
    "ax1.imshow(rotate(montage(test_image_t1[50:-50,:,:]), 90, resize=True), cmap ='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 609
    },
    "id": "YmrelUkRfsdd",
    "outputId": "acaf1ca5-dc51-4691-c2e0-fcddfbf1bcd2"
   },
   "outputs": [],
   "source": [
    "# Skip 50:-50 slices since there is not much to see\n",
    "fig, ax1 = plt.subplots(1, 1, figsize = (15,15))\n",
    "ax1.imshow(rotate(montage(test_mask[60:-60,:,:]), 90, resize=True), cmap ='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HVCU6ECXN4Wl"
   },
   "outputs": [],
   "source": [
    "# Skip 50:-50 slices since there is not much to see\n",
    "fig, ax1 = plt.subplots(1, 1, figsize = (15,15))\n",
    "ax1.imshow(rotate(montage(test_image_t1[50:-50,:,:]), 90, resize=True), cmap ='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "niimg = nl.image.load_img(TRAIN_DATASET_PATH + 'BraTS20_Training_001/BraTS20_Training_001_flair.nii')\n",
    "nimask = nl.image.load_img(TRAIN_DATASET_PATH + 'BraTS20_Training_001/BraTS20_Training_001_seg.nii')\n",
    "\n",
    "fig, axes = plt.subplots(nrows=4, figsize=(30, 40))\n",
    "\n",
    "\n",
    "nlplt.plot_anat(niimg,\n",
    "                title='BraTS20_Training_001_flair.nii plot_anat',\n",
    "                axes=axes[0])\n",
    "\n",
    "nlplt.plot_epi(niimg,\n",
    "               title='BraTS20_Training_001_flair.nii plot_epi',\n",
    "               axes=axes[1])\n",
    "\n",
    "nlplt.plot_img(niimg,\n",
    "               title='BraTS20_Training_001_flair.nii plot_img',\n",
    "               axes=axes[2])\n",
    "\n",
    "nlplt.plot_roi(nimask, \n",
    "               title='BraTS20_Training_001_flair.nii with mask plot_roi',\n",
    "               bg_img=niimg, \n",
    "               axes=axes[3], cmap='Paired')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cOUQj9Lx9CUb"
   },
   "outputs": [],
   "source": [
    "# dice loss as defined above for 4 classes\n",
    "def dice_coef(y_true, y_pred, smooth=1.0):\n",
    "    class_num = 4\n",
    "    for i in range(class_num):\n",
    "        y_true_f = K.flatten(y_true[:,:,:,:,i])\n",
    "        y_pred_f = K.flatten(y_pred[:,:,:,:,i])\n",
    "        intersection = K.sum(y_true_f * y_pred_f)\n",
    "        loss = ((2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth))\n",
    "   #     K.print_tensor(loss, message='loss value for class {} : '.format(SEGMENT_CLASSES[i]))\n",
    "        if i == 0:\n",
    "            total_loss = loss\n",
    "        else:\n",
    "            total_loss = total_loss + loss\n",
    "            \n",
    "    total_loss = total_loss / class_num\n",
    "#    K.print_tensor(total_loss, message=' total dice coef: ')\n",
    "    return total_loss\n",
    "\n",
    "\n",
    " \n",
    "# define per class evaluation of dice coef\n",
    "# inspired by https://github.com/keras-team/keras/issues/9395\n",
    "def dice_coef_necrotic(y_true, y_pred, epsilon=1e-6):\n",
    "    intersection = K.sum(K.abs(y_true[:,:,:,:,1] * y_pred[:,:,:,:,1]))\n",
    "    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,:,1])) + K.sum(K.square(y_pred[:,:,:,1])) + epsilon)\n",
    "\n",
    "def dice_coef_edema(y_true, y_pred, epsilon=1e-6):\n",
    "    intersection = K.sum(K.abs(y_true[:,:,:,:,2] * y_pred[:,:,:,:,2]))\n",
    "    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,:,2])) + K.sum(K.square(y_pred[:,:,:,2])) + epsilon)\n",
    "\n",
    "def dice_coef_enhancing(y_true, y_pred, epsilon=1e-6):\n",
    "    intersection = K.sum(K.abs(y_true[:,:,:,:,3] * y_pred[:,:,:,:,3]))\n",
    "    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,:,3])) + K.sum(K.square(y_pred[:,:,:,3])) + epsilon)\n",
    "\n",
    "\n",
    "# Computing Precision \n",
    "def precision(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    \n",
    "# Computing Sensitivity      \n",
    "def sensitivity(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    return true_positives / (possible_positives + K.epsilon())\n",
    "\n",
    "\n",
    "# Computing Specificity\n",
    "def specificity(y_true, y_pred):\n",
    "    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
    "    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n",
    "    return true_negatives / (possible_negatives + K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "47F7bMJW_u9X"
   },
   "outputs": [],
   "source": [
    "def build_unet(inputs, ker_init):\n",
    "    s = inputs\n",
    "\n",
    "    #Contraction path\n",
    "    c1 = Conv3D(16, (3, 3, 3), activation='relu', kernel_initializer=ker_init, padding='same')(s)\n",
    "    c1 = Dropout(0.1)(c1)\n",
    "    c1 = Conv3D(16, (3, 3, 3), activation='relu', kernel_initializer=ker_init, padding='same')(c1)\n",
    "    p1 = MaxPooling3D((2, 2, 2))(c1)\n",
    "    \n",
    "    c2 = Conv3D(32, (3, 3, 3), activation='relu', kernel_initializer=ker_init, padding='same')(p1)\n",
    "    c2 = Dropout(0.1)(c2)\n",
    "    c2 = Conv3D(32, (3, 3, 3), activation='relu', kernel_initializer=ker_init, padding='same')(c2)\n",
    "    p2 = MaxPooling3D((2, 2, 2))(c2)\n",
    "     \n",
    "    c3 = Conv3D(64, (3, 3, 3), activation='relu', kernel_initializer=ker_init, padding='same')(p2)\n",
    "    c3 = Dropout(0.2)(c3)\n",
    "    c3 = Conv3D(64, (3, 3, 3), activation='relu', kernel_initializer=ker_init, padding='same')(c3)\n",
    "    p3 = MaxPooling3D((2, 2, 2))(c3)\n",
    "     \n",
    "    c4 = Conv3D(128, (3, 3, 3), activation='relu', kernel_initializer=ker_init, padding='same')(p3)\n",
    "    c4 = Dropout(0.2)(c4)\n",
    "    c4 = Conv3D(128, (3, 3, 3), activation='relu', kernel_initializer=ker_init, padding='same')(c4)\n",
    "    p4 = MaxPooling3D(pool_size=(2, 2, 2))(c4)\n",
    "     \n",
    "    c5 = Conv3D(256, (3, 3, 3), activation='relu', kernel_initializer=ker_init, padding='same')(p4)\n",
    "    c5 = Dropout(0.3)(c5)\n",
    "    c5 = Conv3D(256, (3, 3, 3), activation='relu', kernel_initializer=ker_init, padding='same')(c5)\n",
    "    \n",
    "    #Expansive path \n",
    "    u6 = Conv3DTranspose(128, (2, 2, 2), strides=(2, 2, 2), padding='same')(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = Conv3D(128, (3, 3, 3), activation='relu', kernel_initializer=ker_init, padding='same')(u6)\n",
    "    c6 = Dropout(0.2)(c6)\n",
    "    c6 = Conv3D(128, (3, 3, 3), activation='relu', kernel_initializer=ker_init, padding='same')(c6)\n",
    "     \n",
    "    u7 = Conv3DTranspose(64, (2, 2, 2), strides=(2, 2, 2), padding='same')(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = Conv3D(64, (3, 3, 3), activation='relu', kernel_initializer=ker_init, padding='same')(u7)\n",
    "    c7 = Dropout(0.2)(c7)\n",
    "    c7 = Conv3D(64, (3, 3, 3), activation='relu', kernel_initializer=ker_init, padding='same')(c7)\n",
    "     \n",
    "    u8 = Conv3DTranspose(32, (2, 2, 2), strides=(2, 2, 2), padding='same')(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Conv3D(32, (3, 3, 3), activation='relu', kernel_initializer=ker_init, padding='same')(u8)\n",
    "    c8 = Dropout(0.1)(c8)\n",
    "    c8 = Conv3D(32, (3, 3, 3), activation='relu', kernel_initializer=ker_init, padding='same')(c8)\n",
    "     \n",
    "    u9 = Conv3DTranspose(16, (2, 2, 2), strides=(2, 2, 2), padding='same')(c8)\n",
    "    u9 = concatenate([u9, c1])\n",
    "    c9 = Conv3D(16, (3, 3, 3), activation='relu', kernel_initializer=ker_init, padding='same')(u9)\n",
    "    c9 = Dropout(0.1)(c9)\n",
    "    c9 = Conv3D(16, (3, 3, 3), activation='relu', kernel_initializer=ker_init, padding='same')(c9)\n",
    "     \n",
    "    outputs = Conv3D(4, (1, 1, 1), activation='softmax')(c9)\n",
    "     \n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    \n",
    "    return model\n",
    "\n",
    "input_layer = Input((IMG_SIZE, IMG_SIZE, IMG_SIZE, 3))\n",
    "model = build_unet(input_layer, 'he_normal')\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), metrics = ['accuracy',tf.keras.metrics.MeanIoU(num_classes=4), dice_coef, precision, sensitivity, specificity, dice_coef_necrotic, dice_coef_edema ,dice_coef_enhancing] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "T-rMVJScAsRp",
    "outputId": "b3dc7f46-0389-4460-b1b0-2436e79576a4"
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, \n",
    "           show_shapes = True,\n",
    "           show_dtype=False,\n",
    "           show_layer_names = True, \n",
    "           rankdir = 'TB', \n",
    "           expand_nested = False, \n",
    "           dpi = 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K5DPo5baBINt"
   },
   "outputs": [],
   "source": [
    "# lists of directories with studies\n",
    "train_and_val_directories = [f.path for f in os.scandir(TRAIN_DATASET_PATH) if f.is_dir()]\n",
    "\n",
    "# file BraTS20_Training_355 has ill formatted name for for seg.nii file\n",
    "#train_and_val_directories.remove(TRAIN_DATASET_PATH+'BraTS20_Training_355')\n",
    "#train_and_val_directories.remove(TRAIN_DATASET_PATH+'BraTS20_Training_355')\n",
    "\n",
    "\n",
    "def pathListIntoIds(dirList):\n",
    "    x = []\n",
    "    for i in range(0,len(dirList)):\n",
    "        x.append(dirList[i][dirList[i].rfind('/')+1:])\n",
    "    return x\n",
    "\n",
    "train_and_test_ids = pathListIntoIds(train_and_val_directories); \n",
    "\n",
    "    \n",
    "#train_test_ids, val_ids = train_test_split(train_and_test_ids,test_size=0.2) \n",
    "#train_ids, test_ids = train_test_split(train_test_ids,test_size=0.15) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample_train_and_test_ids = train_and_test_ids[:20]\n",
    "train_test_ids, val_ids = train_test_split(sample_train_and_test_ids,test_size=0.2) \n",
    "train_ids, test_ids = train_test_split(sample_train_and_test_ids,test_size=0.15) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Rzl4poLA1EU",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, dim=(IMG_SIZE,IMG_SIZE,IMG_SIZE), batch_size = 1, n_channels = 3, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "        #print('dim - ',dim,'batch_size - ',batch_size,'list_IDs-',list_IDs,'n_channels-',n_channels,'shuffle-',shuffle)\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        Batch_ids = [self.list_IDs[k] for k in indexes]\n",
    "        #print(Batch_ids)\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(Batch_ids)\n",
    "        \n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, Batch_ids):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim, self.n_channels))\n",
    "        #y = np.zeros((self.batch_size*VOLUME_SLICES, 240, 240))\n",
    "        Y = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim))\n",
    "        #print(X.shape) - (100, 128, 128, 128, 3)\n",
    "        # Generate data\n",
    "        for c, i in enumerate(Batch_ids):\n",
    "            case_path = os.path.join(TRAIN_DATASET_PATH, i)\n",
    "\n",
    "            data_path = os.path.join(case_path, f'{i}_flair.nii');\n",
    "            flair = nib.load(data_path).get_fdata()    \n",
    "            \n",
    "            data_path = os.path.join(case_path, f'{i}_t1ce.nii');\n",
    "            ce = nib.load(data_path).get_fdata()\n",
    "\n",
    "            data_path = os.path.join(case_path, f'{i}_t2.nii'); \n",
    "            t2 = nib.load(data_path).get_fdata()\n",
    "            \n",
    "            data_path = os.path.join(case_path, f'{i}_seg.nii');\n",
    "            seg = nib.load(data_path).get_fdata()\n",
    "\n",
    "            #seg=seg.astype(np.uint8)\n",
    "            #seg[seg==4] = 3\n",
    "\n",
    "            #temp_combined_images = np.stack([flair, ce, t2], axis=3)\n",
    "            #temp_combined_images=temp_combined_images[56:184, 56:184, 13:141]\n",
    "            #temp_mask = seg[56:184, 56:184, 13:141]\n",
    "            #print(c,i)#0 BraTS20_Training_016\n",
    "            slice_w = 25\n",
    "            \n",
    "            for j in range(VOLUME_SLICES):\n",
    "                #print('j=',j,'VOLUME_SLICES,c=',VOLUME_SLICES,c)\n",
    "                #print(flair[:,:,flair.shape[0]//2-slice_w+j].shape)\n",
    "                X[j +VOLUME_SLICES*c,:,:,:,0] = cv2.resize(flair[:,:,flair.shape[0]//2-slice_w+j], (IMG_SIZE, IMG_SIZE));\n",
    "                X[j +VOLUME_SLICES*c,:,:,:,1] = cv2.resize(ce[:,:,ce.shape[0]//2-slice_w+j], (IMG_SIZE, IMG_SIZE));\n",
    "                X[j +VOLUME_SLICES*c,:,:,:,2] = cv2.resize(t2[:,:,t2.shape[0]//2-slice_w+j], (IMG_SIZE, IMG_SIZE));\n",
    "                \n",
    "    \n",
    "                Y[j +VOLUME_SLICES*c,:,:,:] = cv2.resize(seg[:,:,seg.shape[0]//2-slice_w+j], (IMG_SIZE, IMG_SIZE));\n",
    "                    \n",
    "        # Generate masks\n",
    "        #y[y==4] = 3;\n",
    "        Y[Y==4] = 3;\n",
    "        mask = tf.one_hot(Y, 4);\n",
    "        #Y = tf.image.resize(mask, (IMG_SIZE, IMG_SIZE));\n",
    "        return X/np.max(X), mask\n",
    "        #return temp_combined_images/np.max(temp_combined_images), temp_mask\n",
    "        \n",
    "training_generator = DataGenerator(train_ids)\n",
    "valid_generator = DataGenerator(val_ids)\n",
    "test_generator = DataGenerator(test_ids)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "case_path = os.path.join(TRAIN_DATASET_PATH, 'BraTS20_Training_001')\n",
    "print(case_path)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data_path = os.path.join(case_path, f'BraTS20_Training_001_flair.nii');\n",
    "flair = nib.load(data_path).get_fdata() \n",
    "\n",
    "data_path = os.path.join(case_path, f'BraTS20_Training_001_t1ce.nii');\n",
    "ce = nib.load(data_path).get_fdata()\n",
    "\n",
    "data_path = os.path.join(case_path, f'BraTS20_Training_001_t2.nii'); \n",
    "t2 = nib.load(data_path).get_fdata()\n",
    "            \n",
    "data_path = os.path.join(case_path, f'BraTS20_Training_001_seg.nii');\n",
    "seg = nib.load(data_path).get_fdata()\n",
    "\n",
    "print(flair.shape)\n",
    "print(ce.shape)\n",
    "print(t2.shape)\n",
    "print(seg.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(cv2.resize(flair[:,:,flair.shape[0]//2-25+60], (IMG_SIZE, IMG_SIZE)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "(flair.shape[0]//2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "(flair.shape[0]//2)-25+60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_ids))\n",
    "print(len(val_ids))\n",
    "print(len(test_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tTpC55fdBMJb"
   },
   "outputs": [],
   "source": [
    "# show number of data for each dir \n",
    "def showDataLayout():\n",
    "    plt.bar([\"Train\",\"Valid\",\"Test\"],\n",
    "    [len(train_ids), len(val_ids), len(test_ids)], align='center',color=[ 'green','red', 'blue'])\n",
    "    #plt.legend()\n",
    "\n",
    "    plt.ylabel('Number of images')\n",
    "    plt.title('Data distribution')\n",
    "    plt.savefig('data2020.png')\n",
    "    plt.show()\n",
    "    \n",
    "showDataLayout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_logger = CSVLogger('training_2020_3D_UNet.log', separator=',', append=False)\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "#     keras.callbacks.EarlyStopping(monitor='loss', min_delta=0,\n",
    "#                               patience=2, verbose=1, mode='auto'),\n",
    "      keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=2, min_lr=0.000001, verbose=1),\n",
    "#  keras.callbacks.ModelCheckpoint(filepath = 'model_.{epoch:02d}-{val_loss:.6f}.m5',\n",
    "#                             verbose=1, save_best_only=True, save_weights_only = True)\n",
    "        csv_logger\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "K.clear_session()\n",
    "\n",
    "history =  model.fit(training_generator,\n",
    "                    epochs=2,\n",
    "                    steps_per_epoch=len(train_ids),\n",
    "                    callbacks= callbacks,\n",
    "                    validation_data = valid_generator\n",
    "                    )  \n",
    "model.save(\"model_unet3d.h5\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "filepath=\"3D-UNet-2018-weights-improvement-{epoch:02d}-{val_accuracy:.3f}.hdf5\" \n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, verbose=1, restore_best_weights=True)\n",
    "\n",
    "csv_logger = CSVLogger('training_2020_3D_UNet.log', separator=',', append=False)\n",
    "\n",
    "history =  model.fit(training_generator,\n",
    "                    epochs=10,\n",
    "                    steps_per_epoch=len(train_ids),\n",
    "                    callbacks= [checkpoint, csv_logger, early_stop],\n",
    "                    validation_data = valid_generator\n",
    "                    )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ load trained model ################\n",
    "model = tf.keras.models.load_model('model_unet3d.h5', \n",
    "                                   custom_objects={ 'accuracy' : tf.keras.metrics.MeanIoU(num_classes=4),\n",
    "                                                   \"dice_coef\": dice_coef,\n",
    "                                                   \"precision\": precision,\n",
    "                                                   \"sensitivity\":sensitivity,\n",
    "                                                   \"specificity\":specificity,\n",
    "                                                   \"dice_coef_necrotic\": dice_coef_necrotic,\n",
    "                                                   \"dice_coef_edema\": dice_coef_edema,\n",
    "                                                   \"dice_coef_enhancing\": dice_coef_enhancing\n",
    "                                                  }, compile=False)\n",
    "\n",
    "history = pd.read_csv('training_2020_3D_UNet.log', sep=',', engine='python')\n",
    "\n",
    "hist=history\n",
    "\n",
    "############### ########## ####### #######\n",
    "\n",
    "# hist=history.history\n",
    "\n",
    "acc=hist['accuracy']\n",
    "val_acc=hist['val_accuracy']\n",
    "\n",
    "epoch=range(len(acc))\n",
    "\n",
    "loss=hist['loss']\n",
    "val_loss=hist['val_loss']\n",
    "\n",
    "train_dice=hist['dice_coef']\n",
    "val_dice=hist['val_dice_coef']\n",
    "\n",
    "f,ax=plt.subplots(1,4,figsize=(16,8))\n",
    "\n",
    "ax[0].plot(epoch,acc,'b',label='Training Accuracy')\n",
    "ax[0].plot(epoch,val_acc,'r',label='Validation Accuracy')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(epoch,loss,'b',label='Training Loss')\n",
    "ax[1].plot(epoch,val_loss,'r',label='Validation Loss')\n",
    "ax[1].legend()\n",
    "\n",
    "ax[2].plot(epoch,train_dice,'b',label='Training dice coef')\n",
    "ax[2].plot(epoch,val_dice,'r',label='Validation dice coef')\n",
    "ax[2].legend()\n",
    "\n",
    "ax[3].plot(epoch,hist['mean_io_u'],'b',label='Training mean IOU')\n",
    "ax[3].plot(epoch,hist['val_mean_io_u'],'r',label='Validation mean IOU')\n",
    "ax[3].legend()\n",
    "plt.savefig('training_result_2018.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "UNet3D-BraTS.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
